% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/word_splitters.R
\name{process_word}
\alias{process_word}
\title{Split a Word into Pieces}
\usage{
process_word(word, sight_words = default_sight_words(), use_lookup = TRUE)
}
\arguments{
\item{word}{Character; a word to process.}

\item{sight_words}{Character vector; words to \emph{not} break down further.
Defaults to the included \code{sight_words} list; to include no sight words,
pass in an empty character vector to this parameter.}

\item{use_lookup}{Logical; whether to use a cached lookup table (if
available) or always process the word from scratch. If the word is not
available in the lookup, processing (and likely a call to the Wiktionary
API) will still occur. You might want to set this value to FALSE if you've
made recent edits to Wiktionary or otherwise want to see if something has
changed recently.}
}
\value{
Character; the word split into pieces.
}
\description{
Recursively splits a word into constituent pieces, based on Wiktionary
annotations. There are two main categories of word pieces used: inflections
(standard verb/noun/comparative adjective forms, defined in practice here as
endings identified in Wiktionary by inflectional function without reference
to the actual form of the ending) and morphemes (typically denoted in
Wiktionary by etymology templates).
}
